{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YcZi_phsDML",
        "outputId": "7e178ae7-3fbe-44be-b62a-77005eafd426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xgd7eHOwpoyA",
        "outputId": "1b995635-e7e5-43ec-e12b-19ce19778f86"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4') # for lemmatizer\n",
        "\n",
        "def process_webpage(url):\n",
        "  # Get the webpage\n",
        "  response = requests.get(url)\n",
        "  html = response.text\n",
        "\n",
        "  # Extract text from html\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  text = soup.get_text(separator=\" \", strip=True)\n",
        "\n",
        "  # Tokenize the text\n",
        "  sentences = sent_tokenize(text)\n",
        "  num_sentences = len(sentences)\n",
        "\n",
        "  words = word_tokenize(text)\n",
        "  num_words = len(words)\n",
        "  token_types = set(words)\n",
        "  num_token_types = len(token_types)\n",
        "\n",
        "  # Lemmatization\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  lemmatized_words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
        "  num_lemma_types = len(set(lemmatized_words))\n",
        "\n",
        "  # Stemming\n",
        "  stemmer = PorterStemmer()\n",
        "  stemmed_words = [stemmer.stem(word.lower()) for word in words]\n",
        "  num_stem_types = len(set(stemmed_words))\n",
        "\n",
        "  return{\n",
        "      \"num_sentences\": num_sentences,\n",
        "      \"num_words\": num_words,\n",
        "      \"num_token_types\": num_token_types,\n",
        "      \"num_lemma_types\": num_lemma_types,\n",
        "      \"num_stem_types\": num_stem_types,\n",
        "      \"sample_sentences\": sentences[:5],\n",
        "      \"sample_words\": words[:20],\n",
        "      \"sample_lemmatized_words\": lemmatized_words[:20],\n",
        "      \"sample_stemmed_words\": stemmed_words[:20]\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lyuu6Y9Xq2CJ",
        "outputId": "7203c951-969d-4edc-bb67-8d5fa91c6ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 234\n",
            "Number of words: 4616\n",
            "Number of token types: 1085\n",
            "Number of lemma types: 900\n",
            "Number of stem types: 849\n",
            "Sample sentences: [\"4 Ways to Tie a Tie - wikiHow Skip to Content Quizzes PRO Courses Hot Guides Tech Help Pro Expert Videos About wikiHow Pro Upgrade QUIZZES All Quizzes Love Quizzes Personality Quizzes Trivia Quizzes Taylor Swift Quizzes EDIT Edit this Article EXPLORE Tech Help Pro About Us Random Article Quizzes Request a New Article Community Dashboard This Or That Game Forums Arts and Entertainment Artwork Books Movies Computers and Electronics Computers Phone Skills Technology Hacks Health Men's Health Mental Health Women's Health Relationships Dating Love Relationship Issues Hobbies and Crafts Crafts Drawing Games Education & Communication Communication Skills Personal Development Studying Personal Care and Style Fashion Hair Care Personal Hygiene Quizzes Love Quizzes Personality Quizzes Fun Games Forums Arts and Entertainment Finance and Business Home and Garden Relationship Quizzes Cars & Other Vehicles Food and Entertaining Personal Care and Style Sports and Fitness Computers and Electronics Health Pets and Animals Travel Education & Communication Hobbies and Crafts Philosophy and Religion Work World Family Life Holidays and Traditions Relationships Youth LOG IN Log in Social login does not work in incognito and private browsers.\", 'Please log in with your username or email to continue.', 'Facebook Google wikiHow Account No account yet?', 'Create an account RANDOM Home Random Browse Articles Quizzes & Games All Quizzes Trending Love Quizzes Personality Quizzes Fun Games Dating Simulator Learn Something New Forums Courses Happiness Hub Explore More Support wikiHow About wikiHow Log in / Sign up Terms of Use wikiHow is where trusted research and expert knowledge come together.', 'Learn why people trust wikiHow Categories Personal Care and Style Fashion Fashion Accessories Ties How to Tie a Tie Download Article Co-authored by Chloée Ohayon-Crosby Last Updated: August 6, 2025 Fact Checked Download Article Four-in-Hand Knot | Traditional Windsor Knot | Pratt Knot | Half Windsor Knot | Video | Q&A | Tips | Show more | Show less ARTICLE VIDEO X This article was co-authored by Chloée Ohayon-Crosby .']\n",
            "Sample words: ['4', 'Ways', 'to', 'Tie', 'a', 'Tie', '-', 'wikiHow', 'Skip', 'to', 'Content', 'Quizzes', 'PRO', 'Courses', 'Hot', 'Guides', 'Tech', 'Help', 'Pro', 'Expert']\n",
            "Sample lemmatized words: ['4', 'way', 'to', 'tie', 'a', 'tie', '-', 'wikihow', 'skip', 'to', 'content', 'quiz', 'pro', 'course', 'hot', 'guide', 'tech', 'help', 'pro', 'expert']\n",
            "Sample stemmed words: ['4', 'way', 'to', 'tie', 'a', 'tie', '-', 'wikihow', 'skip', 'to', 'content', 'quizz', 'pro', 'cours', 'hot', 'guid', 'tech', 'help', 'pro', 'expert']\n"
          ]
        }
      ],
      "source": [
        "url = \"https://www.wikihow.com/Tie-a-Tie\"\n",
        "result = process_webpage(url)\n",
        "\n",
        "print(\"Number of sentences:\",result[\"num_sentences\"])\n",
        "print(\"Number of words:\",result[\"num_words\"])\n",
        "print(\"Number of token types:\",result[\"num_token_types\"])\n",
        "print(\"Number of lemma types:\",result[\"num_lemma_types\"])\n",
        "print(\"Number of stem types:\",result[\"num_stem_types\"])\n",
        "\n",
        "print(\"Sample sentences:\",result[\"sample_sentences\"])\n",
        "print(\"Sample words:\",result[\"sample_words\"])\n",
        "print(\"Sample lemmatized words:\",result[\"sample_lemmatized_words\"])\n",
        "print(\"Sample stemmed words:\",result[\"sample_stemmed_words\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL_z-bP3sZjW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Provided Answer below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url=\"https://en.wikipedia.org/wiki/Natural_language_preprocessing\"\n",
        "\n",
        "custom_user_agent = 'Mozilla/5.0 (Windows NT 10.0;Win64;x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'\n",
        "\n",
        "# Create a dictionary for headers, including User-Agent\n",
        "headers = {\n",
        "    'User-Agent':custom_user_agent\n",
        "    }\n",
        "\n",
        "# Create a Request object with the URL and headers\n",
        "req = urllib.request.Request(url,headers=headers)\n",
        "\n",
        "print(\"Ready to collect pages......\")\n",
        "\n",
        "# Download the webpage of a given link\n",
        "with urllib.request.urlopen(req) as response:\n",
        "    html = response.read().decode('utf-8')\n",
        "    \n",
        "print('HTML page downloaded')\n",
        "\n",
        "# Extract the text content of the page\n",
        "text = BeautifulSoup(html, \"lxml\").get_text()\n",
        "\n",
        "# Split text into sentences and count sentences\n",
        "sentences = nltk.tokenize.sent_tokenize(text)\n",
        "print(\"Number of sentences:\" + str(len(sentences)))\n",
        "\n",
        "# Split text into tokens and count token types\n",
        "tokens = nltk.tokenize.word_tokenize(text)\n",
        "print('Number of tokens:' + str(len(tokens)))\n",
        "token_types = list(set(tokens))\n",
        "print(\"Number of token types:\" + str(len(token_types)))\n",
        "\n",
        "# Find lemmas or stems of tokens and count lemma types\n",
        "# Do stemming on the tokens and count unique stemmed tokens\n",
        "wnl = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "stemmer = nltk.stem.porter.PorterStemmer()\n",
        "lemma_types = set()\n",
        "stemmed_types = set()\n",
        "\n",
        "for token_type in token_types:\n",
        "    lemma_types.add(wnl.lemmatize(token_type))\n",
        "    stemmed_types.add(stemmer.stem(token_type))\n",
        "    \n",
        "print(\"Number of lemma types:\" + str(len(lemma_types)))\n",
        "print(\"Number of stemmed types:\" + str(len(stemmed_types)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
