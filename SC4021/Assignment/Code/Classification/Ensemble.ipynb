{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "medieval-murder",
   "metadata": {},
   "source": [
    "## 1. Polarity detection (positive and negative)\n",
    "### Train: train_pos_neg.csv, Test: test_pos_neg.csv\n",
    "\n",
    "#### Training data source: different datasets combined\n",
    "\n",
    "Both train_pos_neg.csv and test_pos_neg.csv has positive and negative labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "incorporated-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from joblib import load\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-popularity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beneficial-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv(\"train_pos_neg_preprocessed.csv\", encoding = 'ISO-8859-1')\n",
    "dfTest = pd.read_csv(\"test_pos_neg_preprocessed.csv\", encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rational-implement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4709\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAHoCAYAAAC4tr6OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqSUlEQVR4nO3df1RVdb7/8dcBBH/BUVBAklJLvTpkq/QO4tzUyd9LB0tLSyMtUovUuGoWt+Za997BsrlaM0wt+wWmJjNj6UzJMJopmr+1Icsxu5kmJggqHEARBPf3j7nu7z1iJoju84HnY62zpr3Ph8P7tGbn0332OcdlWZYlAAAAw/g5PQAAAEB9EDEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjBTg9ADXyvnz53Xs2DEFBwfL5XI5PQ4AALgClmWprKxMUVFR8vO7/LmWRhsxx44dU3R0tNNjAACAesjLy1PHjh0vu6bRRkxwcLCkf/xLCAkJcXgaAABwJUpLSxUdHW3/OX45jTZiLryEFBISQsQAAGCYK7kUhAt7AQCAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYKcDpAdDwOj2zxukRcB0dfnGk0yPgOuL4blo4vi+PMzEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMdFURM3/+fLlcLiUnJ9v7LMvS888/r6ioKLVo0UIDBw7Uvn37vH6usrJSM2bMULt27dSqVSvFx8fr6NGjXmuKi4uVkJAgt9stt9uthIQElZSUXM24AACgEal3xOzatUtvvPGGevXq5bV/wYIFWrhwodLS0rRr1y5FRkZqyJAhKisrs9ckJydr1apVyszM1Keffqry8nKNGjVKNTU19poJEyYoNzdX2dnZys7OVm5urhISEuo7LgAAaGTqFTHl5eWaOHGi3nzzTbVt29beb1mWXnnlFT377LMaM2aMYmJitGTJEp05c0bvvfeeJMnj8ejtt9/Wf//3f2vw4MG6/fbbtWzZMn3xxRf6+OOPJUn79+9Xdna23nrrLcXFxSkuLk5vvvmmPvroIx04cKABnjYAADBdvSLmiSee0MiRIzV48GCv/YcOHVJBQYGGDh1q7wsKCtKAAQO0detWSdKePXt07tw5rzVRUVGKiYmx12zbtk1ut1uxsbH2mr59+8rtdttrAABA0xZQ1x/IzMzUZ599pl27dtW6r6CgQJIUERHhtT8iIkLfffedvSYwMNDrDM6FNRd+vqCgQOHh4bUePzw83F5zscrKSlVWVtrbpaWldXhWAADANHU6E5OXl6cnn3xSy5YtU/PmzX9wncvl8tq2LKvWvotdvOZS6y/3OPPnz7cvAna73YqOjr7s7wMAAGarU8Ts2bNHhYWF6t27twICAhQQEKCcnBz95je/UUBAgH0G5uKzJYWFhfZ9kZGRqqqqUnFx8WXXHD9+vNbvLyoqqnWW54KUlBR5PB77lpeXV5enBgAADFOniBk0aJC++OIL5ebm2rc+ffpo4sSJys3NVZcuXRQZGal169bZP1NVVaWcnBz169dPktS7d281a9bMa01+fr6+/PJLe01cXJw8Ho927txpr9mxY4c8Ho+95mJBQUEKCQnxugEAgMarTtfEBAcHKyYmxmtfq1atFBYWZu9PTk5Wamqqunbtqq5duyo1NVUtW7bUhAkTJElut1uJiYmaPXu2wsLCFBoaqjlz5ujWW2+1LxTu0aOHhg8frilTpmjx4sWSpKlTp2rUqFHq3r37VT9pAABgvjpf2Ptj5s6dq4qKCiUlJam4uFixsbFau3atgoOD7TWLFi1SQECAxo0bp4qKCg0aNEgZGRny9/e31yxfvlwzZ86038UUHx+vtLS0hh4XAAAYymVZluX0ENdCaWmp3G63PB5Pk3tpqdMza5weAdfR4RdHOj0CriOO76alKR7fdfnzm+9OAgAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYqU4R8/rrr6tXr14KCQlRSEiI4uLi9Je//MW+37IsPf/884qKilKLFi00cOBA7du3z+sxKisrNWPGDLVr106tWrVSfHy8jh496rWmuLhYCQkJcrvdcrvdSkhIUElJSf2fJQAAaHTqFDEdO3bUiy++qN27d2v37t266667NHr0aDtUFixYoIULFyotLU27du1SZGSkhgwZorKyMvsxkpOTtWrVKmVmZurTTz9VeXm5Ro0apZqaGnvNhAkTlJubq+zsbGVnZys3N1cJCQkN9JQBAEBj4LIsy7qaBwgNDdXLL7+sRx55RFFRUUpOTtbTTz8t6R9nXSIiIvTSSy9p2rRp8ng8at++vZYuXarx48dLko4dO6bo6GhlZWVp2LBh2r9/v3r27Knt27crNjZWkrR9+3bFxcXpq6++Uvfu3a9ortLSUrndbnk8HoWEhFzNUzROp2fWOD0CrqPDL450egRcRxzfTUtTPL7r8ud3va+JqampUWZmpk6fPq24uDgdOnRIBQUFGjp0qL0mKChIAwYM0NatWyVJe/bs0blz57zWREVFKSYmxl6zbds2ud1uO2AkqW/fvnK73faaS6msrFRpaanXDQAANF51jpgvvvhCrVu3VlBQkB577DGtWrVKPXv2VEFBgSQpIiLCa31ERIR9X0FBgQIDA9W2bdvLrgkPD6/1e8PDw+01lzJ//nz7Ghq3263o6Oi6PjUAAGCQOkdM9+7dlZubq+3bt+vxxx/XpEmT9Pe//92+3+Vyea23LKvWvotdvOZS63/scVJSUuTxeOxbXl7elT4lAABgoDpHTGBgoG655Rb16dNH8+fP12233aZXX31VkZGRklTrbElhYaF9diYyMlJVVVUqLi6+7Jrjx4/X+r1FRUW1zvL8X0FBQfa7pi7cAABA43XVnxNjWZYqKyvVuXNnRUZGat26dfZ9VVVVysnJUb9+/SRJvXv3VrNmzbzW5Ofn68svv7TXxMXFyePxaOfOnfaaHTt2yOPx2GsAAAAC6rL43/7t3zRixAhFR0errKxMmZmZ2rhxo7Kzs+VyuZScnKzU1FR17dpVXbt2VWpqqlq2bKkJEyZIktxutxITEzV79myFhYUpNDRUc+bM0a233qrBgwdLknr06KHhw4drypQpWrx4sSRp6tSpGjVq1BW/MwkAADR+dYqY48ePKyEhQfn5+XK73erVq5eys7M1ZMgQSdLcuXNVUVGhpKQkFRcXKzY2VmvXrlVwcLD9GIsWLVJAQIDGjRuniooKDRo0SBkZGfL397fXLF++XDNnzrTfxRQfH6+0tLSGeL4AAKCRuOrPifFVfE4Mmoqm+DkSTRnHd9PSFI/v6/I5MQAAAE4iYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGAkIgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGKlOETN//nz98z//s4KDgxUeHq67775bBw4c8FpjWZaef/55RUVFqUWLFho4cKD27dvntaayslIzZsxQu3bt1KpVK8XHx+vo0aNea4qLi5WQkCC32y23262EhASVlJTU71kCAIBGp04Rk5OToyeeeELbt2/XunXrVF1draFDh+r06dP2mgULFmjhwoVKS0vTrl27FBkZqSFDhqisrMxek5ycrFWrVikzM1OffvqpysvLNWrUKNXU1NhrJkyYoNzcXGVnZys7O1u5ublKSEhogKcMAAAaA5dlWVZ9f7ioqEjh4eHKyclR//79ZVmWoqKilJycrKefflrSP866RERE6KWXXtK0adPk8XjUvn17LV26VOPHj5ckHTt2TNHR0crKytKwYcO0f/9+9ezZU9u3b1dsbKwkafv27YqLi9NXX32l7t27/+hspaWlcrvd8ng8CgkJqe9TNFKnZ9Y4PQKuo8MvjnR6BFxHHN9NS1M8vuvy5/dVXRPj8XgkSaGhoZKkQ4cOqaCgQEOHDrXXBAUFacCAAdq6daskac+ePTp37pzXmqioKMXExNhrtm3bJrfbbQeMJPXt21dut9tec7HKykqVlpZ63QAAQONV74ixLEuzZs3Sv/zLvygmJkaSVFBQIEmKiIjwWhsREWHfV1BQoMDAQLVt2/aya8LDw2v9zvDwcHvNxebPn29fP+N2uxUdHV3fpwYAAAxQ74iZPn269u7dqxUrVtS6z+VyeW1bllVr38UuXnOp9Zd7nJSUFHk8HvuWl5d3JU8DAAAYql4RM2PGDP35z3/Whg0b1LFjR3t/ZGSkJNU6W1JYWGifnYmMjFRVVZWKi4svu+b48eO1fm9RUVGtszwXBAUFKSQkxOsGAAAarzpFjGVZmj59uj744AN98skn6ty5s9f9nTt3VmRkpNatW2fvq6qqUk5Ojvr16ydJ6t27t5o1a+a1Jj8/X19++aW9Ji4uTh6PRzt37rTX7NixQx6Px14DAACatoC6LH7iiSf03nvv6U9/+pOCg4PtMy5ut1stWrSQy+VScnKyUlNT1bVrV3Xt2lWpqalq2bKlJkyYYK9NTEzU7NmzFRYWptDQUM2ZM0e33nqrBg8eLEnq0aOHhg8frilTpmjx4sWSpKlTp2rUqFFX9M4kAADQ+NUpYl5//XVJ0sCBA732p6ena/LkyZKkuXPnqqKiQklJSSouLlZsbKzWrl2r4OBge/2iRYsUEBCgcePGqaKiQoMGDVJGRob8/f3tNcuXL9fMmTPtdzHFx8crLS2tPs8RAAA0Qlf1OTG+jM+JQVPRFD9Hoinj+G5amuLxfd0+JwYAAMApRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxU54jZtGmTfvGLXygqKkoul0urV6/2ut+yLD3//POKiopSixYtNHDgQO3bt89rTWVlpWbMmKF27dqpVatWio+P19GjR73WFBcXKyEhQW63W263WwkJCSopKanzEwQAAI1TnSPm9OnTuu2225SWlnbJ+xcsWKCFCxcqLS1Nu3btUmRkpIYMGaKysjJ7TXJyslatWqXMzEx9+umnKi8v16hRo1RTU2OvmTBhgnJzc5Wdna3s7Gzl5uYqISGhHk8RAAA0RgF1/YERI0ZoxIgRl7zPsiy98sorevbZZzVmzBhJ0pIlSxQREaH33ntP06ZNk8fj0dtvv62lS5dq8ODBkqRly5YpOjpaH3/8sYYNG6b9+/crOztb27dvV2xsrCTpzTffVFxcnA4cOKDu3bvX9/kCAIBGokGviTl06JAKCgo0dOhQe19QUJAGDBigrVu3SpL27Nmjc+fOea2JiopSTEyMvWbbtm1yu912wEhS37595Xa77TUAAKBpq/OZmMspKCiQJEVERHjtj4iI0HfffWevCQwMVNu2bWutufDzBQUFCg8Pr/X44eHh9pqLVVZWqrKy0t4uLS2t/xMBAAA+75q8O8nlcnltW5ZVa9/FLl5zqfWXe5z58+fbFwG73W5FR0fXY3IAAGCKBo2YyMhISap1tqSwsNA+OxMZGamqqioVFxdfds3x48drPX5RUVGtszwXpKSkyOPx2Le8vLyrfj4AAMB3NWjEdO7cWZGRkVq3bp29r6qqSjk5OerXr58kqXfv3mrWrJnXmvz8fH355Zf2mri4OHk8Hu3cudNes2PHDnk8HnvNxYKCghQSEuJ1AwAAjVedr4kpLy/XN998Y28fOnRIubm5Cg0N1Y033qjk5GSlpqaqa9eu6tq1q1JTU9WyZUtNmDBBkuR2u5WYmKjZs2crLCxMoaGhmjNnjm699Vb73Uo9evTQ8OHDNWXKFC1evFiSNHXqVI0aNYp3JgEAAEn1iJjdu3fr5z//ub09a9YsSdKkSZOUkZGhuXPnqqKiQklJSSouLlZsbKzWrl2r4OBg+2cWLVqkgIAAjRs3ThUVFRo0aJAyMjLk7+9vr1m+fLlmzpxpv4spPj7+Bz+bBgAAND0uy7Isp4e4FkpLS+V2u+XxeJrcS0udnlnj9Ai4jg6/ONLpEXAdcXw3LU3x+K7Ln998dxIAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAADASEQMAAAwEhEDAACMRMQAAAAjETEAAMBIRAwAADASEQMAAIxExAAAACMRMQAAwEg+HzGvvfaaOnfurObNm6t3797avHmz0yMBAAAf4NMR8/vf/17Jycl69tln9be//U133nmnRowYoSNHjjg9GgAAcJhPR8zChQuVmJioRx99VD169NArr7yi6Ohovf76606PBgAAHOazEVNVVaU9e/Zo6NChXvuHDh2qrVu3OjQVAADwFQFOD/BDTpw4oZqaGkVERHjtj4iIUEFBQa31lZWVqqystLc9Ho8kqbS09NoO6oPOV55xegRcR03x/+NNGcd309IUj+8Lz9myrB9d67MRc4HL5fLatiyr1j5Jmj9/vl544YVa+6Ojo6/ZbIAvcL/i9AQArpWmfHyXlZXJ7XZfdo3PRky7du3k7+9f66xLYWFhrbMzkpSSkqJZs2bZ2+fPn9epU6cUFhZ2yehB41JaWqro6Gjl5eUpJCTE6XEANCCO76bFsiyVlZUpKirqR9f6bMQEBgaqd+/eWrdune655x57/7p16zR69Oha64OCghQUFOS1r02bNtd6TPiYkJAQ/iMHNFIc303Hj52BucBnI0aSZs2apYSEBPXp00dxcXF64403dOTIET322GNOjwYAABzm0xEzfvx4nTx5Uv/xH/+h/Px8xcTEKCsrSzfddJPTowEAAIf5dMRIUlJSkpKSkpweAz4uKChI8+bNq/WSIgDzcXzjh7isK3kPEwAAgI/x2Q+7AwAAuBwiBgAAGImIAQAARiJiAACAkYgYAABgJCIGjZJlWSosLHR6DAD18GPHbnV1tXbu3HmdpoEvI2JgpJYtW6qoqMjeHj58uPLz8+3twsJCdejQwYnRAFylDh06eIVMjx49dOTIEXv75MmTiouLc2I0+BgiBkY6e/as19e0b9myRRUVFV5r+AgkwEwXH7tHjx5VdXX1ZdegaSJi0Gjx7eVA48XxDYmIAQAAhvL5704CLsXlcnn9TezibQDmcrlcKisrU/PmzWVZllwul8rLy1VaWipJ9v8CfHcSjOTn5ye3222HS0lJiUJCQuTn94+Ti5ZlqbS0VDU1NU6OCaAe/Pz8vP5SciFkLt7m+AZnYmCk9PR0p0cAcI1s2LDB6RFgCM7EwEjV1dUKCKDBgcaoqKhI7du3d3oMGIALe2GkqKgozZkzR/v373d6FAAN7IYbbtC9996rv/zlL7yVGpdFxMBI//qv/6oPP/xQMTExiouL09tvv63y8nKnxwLQAJYsWaLS0lL94he/UHR0tH75y1/q4MGDTo8FH8TLSTDa5s2b9c4772jlypWSpHvvvVePPvqofvaznzk8GYCrlZeXp3feeUdLlizRd999p/79++vRRx/V2LFj1bx5c6fHgw8gYtAonD59WpmZmcrIyNCWLVvUtWtXJSYmau7cuU6PBqABrF+/Xunp6Vq1apUCAwP1wAMP6LXXXnN6LDiMiEGjs2bNGj300EMqKSnhLZhAI/P+++9r6tSpHN+QxDUxaCTOnDmj9PR09e/fX/Hx8QoLC9OvfvUrp8cC0AAOHz6sefPmqVOnTho/frzuuOMOLV++3Omx4AM4EwOjbd68Wenp6Vq5cqVqamp07733KjExUf3793d6NABX4ezZs/rjH/+o9PR0bdq0STfccIMmT56shx9+WJ06dXJ6PPgIPmgDRkpNTVVGRoYOHjyoPn366OWXX9YDDzygkJAQp0cDcJWmTp2qP/zhDzp79qxGjx6tNWvWaOjQoXy1CGrhTAyM1L59ez344INKTExUTEyM0+MAaEC9evVSYmKiEhISFBoa6vQ48GFEDIx07tw5NWvWzOkxAAAO4uUkGOn111+/onUzZ868xpMAaGizZs26onULFy68xpPA13EmBkbq3Lnzj65xuVz69ttvr8M0ABrSwIEDf/T6F5fLpU8++eQ6TQRfRcQAAAAj8TkxMNJdd92lkpISp8cAcA106dJFJ0+edHoMGIAzMTCSn5+fCgoKFB4e7vQoABoYxzeuFGdiAACAkXh3EoxVVlb2o99ky4ffAWb6+9//roKCgsuu6dWr13WaBr6Kl5NgJD8/v8u+e8GyLLlcLr4gDjDQheP7Un88XdjP8Q2JMzEw2MqVK/k0T6CR2rFjh9q3b+/0GPBxnImBkbjwD2i8OL5xpbiwFwBgnKKiIqdHgA8gYmCkm266Sf7+/k6PAeAaGDBggAIDA2vttyxLWVlZGjNmjDp27OjAZPA1vJwEAPBp3377rd555x0tWbJE5eXlGjlypMaOHat77rnH6dHgMC7shZHuuOOOK1r32WefXeNJAFwLZ8+e1cqVK/XWW29p+/btGjJkiPLz85Wbm6uYmBinx4OPIGJgpNGjRzs9AoBrJCkpSZmZmerevbsefPBBvf/++woLC1OzZs3k58dVEPj/eDkJAOBTAgIC9PTTT+uZZ55RcHCwvb9Zs2b6/PPP1bNnTwengy8hadGo5OTkKCsrS8XFxU6PAqCe3n33Xe3cuVMdOnTQ+PHj9dFHH6m6utrpseCDOBMDI7388ssqLy/XCy+8IOkf71oYMWKE1q5dK0kKDw/X+vXr9ZOf/MTJMQFchcOHDys9PV0ZGRk6c+aMTp06pd///ve69957nR4NPoIzMTDSihUrvE4pr1y5Ups2bdLmzZt14sQJ9enTxw4cAGbq1KmTXnjhBR0+fFhLly7V2LFj9eCDD6pjx46aOXOm0+PBB3AmBkZq27attm7dqh49ekiSHn74YVVXV2vp0qWSpO3bt+u+++5TXl6ek2MCaGCnTp3Su+++q/T0dH3++edOjwOHcSYGRjp37pyCgoLs7W3btqlfv372dlRUlE6cOOHEaACuodDQUCUnJxMwkMRbrGGoW265RZs2bVKXLl105MgRff311xowYIB9/9GjRxUWFubghADqq6SkRCtWrNDjjz8uSZo4caIqKirs+wMCAvTGG2+oTZs2Dk0IX8GZGBjp8ccf1/Tp05WYmKgRI0YoLi7O6xqZTz75RLfffruDEwKorzfffFNbtmyxt//85z/Lz89Pbrdbbrdbe/fu1SuvvOLcgPAZRAyMNG3aNL366qs6deqU+vfvr/fff9/r/mPHjumRRx5xaDoAV2PlypWaMGGC174FCxYoPT1d6enpmj9/vv70pz85NB18CRf2AgB8Srt27bR161Z169ZNktSnTx+tXr3a/tLHb7/9Vr169VJ5ebmTY8IHcE0MjPb999/r/fff19dffy2Xy6Vu3bppzJgxuuGGG5weDUA9nTlzRlVVVfb27t27ve4/ffq0zp8/f73Hgg8iYmCs1157TbNmzVJVVZXcbrcsy1JpaameeuopLVy4UElJSU6PCKAeunTpos8+++wHv+hx9+7d6ty583WeCr6Ia2JgpDVr1mjmzJmaPn26vv/+exUXF6ukpETff/+9kpKS9OSTTyorK8vpMQHUwz333KPnnntOBQUFte7Lz8/XvHnzdM899zgwGXwN18TASAMGDNCdd96p//qv/7rk/c8995w2b96snJyc6zwZgKtVVlam2NhYHT16VAkJCerWrZtcLpe++uorLVu2TDfccIN27tzp9eWQaJqIGBgpJCREu3btUvfu3S95/4EDB9SnTx+VlZVd58kANITi4mKlpKToD3/4g0pKSiRJbdq00bhx45SamqrQ0FBnB4RPIGJgpNatW2vv3r3q0qXLJe/n3QtA42BZloqKiiRJ7du3l8vlcngi+BKuiYGRfvKTn1z2cyJWr17NN1gDhiosLLT/2eVyKTw8XOHh4XbAVFdXa+fOnU6NBx9CxMBISUlJevbZZ/Xaa6+purra3l9dXa3f/e53eu655+yPLAdglg4dOniFTI8ePXTkyBF7++TJk4qLi3NiNPgY3mINI02aNElffPGFpk+frpSUFN18882SpIMHD6q8vFwzZ87U5MmTnR0SQL1cfJXD0aNHvf6ycqk1aJqIGBjr17/+te677z6tWLFCX3/9tSSpf//+uv/++9W3b1+HpwNwLXFtDCQiBoY6c+aMnnrqKa1evVrnzp3ToEGD9Nvf/lbt2rVzejQAwHXCNTEw0rx585SRkaGRI0fqgQce0Mcff8w1MEAj4XK5VFZWptLSUnk8HrlcLpWXl6u0tNS+ARJvsYahbr75Zv3qV7/S/fffL0nauXOnfvazn+ns2bPy9/d3eDoAV8PPz8/r5SLLsi65XVNT48R48CG8nAQj5eXl6c4777S3f/rTnyogIEDHjh1TdHS0g5MBuFobNmxwegQYgoiBkWpqahQYGOi1LyAgoNY7GACYZ8CAAU6PAEMQMTCSZVmaPHmygoKC7H1nz57VY489platWtn7PvjgAyfGA3AVLn456VJcLhd/aQERAzNNmjSp1r4HH3zQgUkANLRVq1b94H1bt27Vb3/7Wz4nBpK4sBcAYICvvvpKKSkp+vDDDzVx4kT953/+p2688Uanx4LDeIs1AMBnHTt2TFOmTFGvXr1UXV2t3NxcLVmyhICBJCIGAOCDPB6Pnn76ad1yyy3at2+f1q9frw8//FAxMTFOjwYfwjUxAACfsmDBAr300kuKjIzUihUrNHr0aKdHgo/imhgAgE/x8/NTixYtNHjw4Mt+eCXvPgRnYgAAPuWhhx7iCx5xRTgTAwAAjMSFvQAAwEhEDAAAMBIRAwAAjETEAAAAIxExAIywceNGuVwulZSUOD0KAB9BxACok8LCQk2bNk033nijgoKCFBkZqWHDhmnbtm0N9jsGDhyo5ORkr339+vVTfn6+3G53g/2e+po8ebLuvvtup8cAmjw+JwZAnYwdO1bnzp3TkiVL1KVLFx0/flzr16/XqVOnrunvDQwMVGRk5DX9HQAMYwHAFSouLrYkWRs3bvzBNSUlJdaUKVOs9u3bW8HBwdbPf/5zKzc3175/3rx51m233Wa9++671k033WSFhIRY48ePt0pLSy3LsqxJkyZZkrxuhw4dsjZs2GBJsoqLiy3Lsqz09HTL7XZbH374odWtWzerRYsW1tixY63y8nIrIyPDuummm6w2bdpY06dPt6qrq+3fX1lZaT311FNWVFSU1bJlS+unP/2ptWHDBvv+C4+bnZ1t/dM//ZPVqlUra9iwYdaxY8fs+S+e7//+PIDrh5eTAFyx1q1bq3Xr1lq9erUqKytr3W9ZlkaOHKmCggJlZWVpz549uuOOOzRo0CCvMzUHDx7U6tWr9dFHH+mjjz5STk6OXnzxRUnSq6++qri4OE2ZMkX5+fnKz89XdHT0Jec5c+aMfvOb3ygzM1PZ2dnauHGjxowZo6ysLGVlZWnp0qV64403tHLlSvtnHn74YW3ZskWZmZnau3ev7rvvPg0fPlz/8z//4/W4v/71r7V06VJt2rRJR44c0Zw5cyRJc+bM0bhx4zR8+HB7vn79+jXIv18AdeR0RQEwy8qVK622bdtazZs3t/r162elpKRYn3/+uWVZlrV+/XorJCTEOnv2rNfP3HzzzdbixYsty/rHmYyWLVvaZ14sy7KeeuopKzY21t4eMGCA9eSTT3o9xqXOxEiyvvnmG3vNtGnTrJYtW1plZWX2vmHDhlnTpk2zLMuyvvnmG8vlclnff/+912MPGjTISklJ+cHH/d3vfmdFRETY25MmTbJGjx59Rf++AFw7XBMDoE7Gjh2rkSNHavPmzdq2bZuys7O1YMECvfXWWyoqKlJ5ebnCwsK8fqaiokIHDx60tzt16qTg4GB7u0OHDiosLKzzLC1bttTNN99sb0dERKhTp05q3bq1174Lj/3ZZ5/Jsix169bN63EqKyu9Zr74ces7H4Bri4gBUGfNmzfXkCFDNGTIEP37v/+7Hn30Uc2bN09JSUnq0KGDNm7cWOtn2rRpY/9zs2bNvO5zuVw6f/58nee41ONc7rHPnz8vf39/7dmzp9a3I//f8LnUY1h8zRzgc4gYAFetZ8+eWr16te644w4VFBQoICBAnTp1qvfjBQYGqqampuEG/F+33367ampqVFhYqDvvvLPej3Ot5gNQN1zYC+CKnTx5UnfddZeWLVumvXv36tChQ/rjH/+oBQsWaPTo0Ro8eLDi4uJ09913669//asOHz6srVu36rnnntPu3buv+Pd06tRJO3bs0OHDh3XixIl6naW5lG7dumnixIl66KGH9MEHH+jQoUPatWuXXnrpJWVlZdVpvr179+rAgQM6ceKEzp071yDzAagbIgbAFWvdurViY2O1aNEi9e/fXzExMfrlL3+pKVOmKC0tTS6XS1lZWerfv78eeeQRdevWTffff78OHz6siIiIK/49c+bMkb+/v3r27Kn27dvryJEjDfYc0tPT9dBDD2n27Nnq3r274uPjtWPHjh98B9SlTJkyRd27d1efPn3Uvn17bdmypcHmA3DlXBYv9AIAAANxJgYAABiJiAEAAEYiYgAAgJGIGAAAYCQiBgAAGImIAQAARiJiAACAkYgYAABgJCIGAAAYiYgBAABGImIAAICRiBgAAGCk/wc5A3+9Pq+howAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Class count\n",
    "count_positive, count_negative = dfTrain.Sentiment.value_counts()\n",
    "print(count_negative)\n",
    "\n",
    "#Divide by class\n",
    "dataset_positive = dfTrain[dfTrain['Sentiment'] == 'POSITIVE']\n",
    "dataset_negative = dfTrain[dfTrain['Sentiment'] == 'NEGATIVE']\n",
    "\n",
    "dataset_positive_under = dataset_positive.sample(count_negative)\n",
    "\n",
    "dataset_balance = pd.concat([dataset_positive_under, dataset_negative], axis=0)\n",
    "dataset_balance.Sentiment.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "revolutionary-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Split the model into Train and Test Dataset\n",
    "# X_train, X_test, y_train, y_test = model_selection.train_test_split(dataset_balance['Headline_final'],dataset_balance['Label'],test_size=0.3)\n",
    "\n",
    "\n",
    "X_train, y_train = dataset_balance['Headline_final'], dataset_balance['Sentiment']\n",
    "X_test, y_test = dfTest['Headline_final'], dfTest['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-ground",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-filter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "australian-possible",
   "metadata": {},
   "source": [
    "# Ensemble Voting Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-forward",
   "metadata": {},
   "source": [
    "### Ensemble soft voting method using random forest, svm, and logistic regression with unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "coated-advocate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble model: 0.7460711331679074\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.83      0.62      0.71       601\n",
      "    POSITIVE       0.70      0.87      0.78       608\n",
      "\n",
      "    accuracy                           0.75      1209\n",
      "   macro avg       0.76      0.75      0.74      1209\n",
      "weighted avg       0.76      0.75      0.74      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined as per your dataset\n",
    "\n",
    "# Define pipelines for each of the classifiers including the TF-IDF vectorization\n",
    "rf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svm', SVC(probability=True, random_state=42))  # Enable probability for soft voting\n",
    "])\n",
    "\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression(random_state=42))  # Enable probability for soft voting\n",
    "])\n",
    "\n",
    "\n",
    "# Create the ensemble model using voting classifier\n",
    "# Here 'voting' is set to 'hard'. Change to 'soft' for soft voting if desired\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', rf_pipeline),\n",
    "    ('svm', svm_pipeline),\n",
    "    ('lr', lr_pipeline)\n",
    "], voting='soft')\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the ensemble model\n",
    "predictions = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of ensemble model: {accuracy}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-rental",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "artificial-joining",
   "metadata": {},
   "source": [
    "### Ensemble soft voting method using random forest, svm, and logistic regression with unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "golden-stockholm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble model: 0.7411083540115798\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.81      0.63      0.71       601\n",
      "    POSITIVE       0.70      0.85      0.77       608\n",
      "\n",
      "    accuracy                           0.74      1209\n",
      "   macro avg       0.75      0.74      0.74      1209\n",
      "weighted avg       0.75      0.74      0.74      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined as per your dataset\n",
    "\n",
    "# Define pipelines for each of the classifiers including the TF-IDF vectorization\n",
    "rf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('svm', SVC(probability=True, random_state=42))  # Enable probability for soft voting\n",
    "])\n",
    "\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('logreg', LogisticRegression(random_state=42))  # Enable probability for soft voting\n",
    "])\n",
    "\n",
    "\n",
    "# Create the ensemble model using voting classifier\n",
    "# Here 'voting' is set to 'hard'. Change to 'soft' for soft voting if desired\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', rf_pipeline),\n",
    "    ('svm', svm_pipeline),\n",
    "    ('lr', lr_pipeline)\n",
    "], voting='soft')\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the ensemble model\n",
    "predictions = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of ensemble model: {accuracy}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-pattern",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-cradle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reliable-school",
   "metadata": {},
   "source": [
    "### Ensemble hard voting method using random forest, svm, and logistic regression with unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "established-bidder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble model: 0.7377998345740281\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.83      0.60      0.69       601\n",
      "    POSITIVE       0.69      0.88      0.77       608\n",
      "\n",
      "    accuracy                           0.74      1209\n",
      "   macro avg       0.76      0.74      0.73      1209\n",
      "weighted avg       0.76      0.74      0.73      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined as per your dataset\n",
    "\n",
    "# Define pipelines for each of the classifiers including the TF-IDF vectorization\n",
    "rf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svm', SVC(probability=True, random_state=42))  # Enable probability for soft voting\n",
    "])\n",
    "\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression(random_state=42))  # Enable probability for soft voting\n",
    "])\n",
    "\n",
    "\n",
    "# Create the ensemble model using voting classifier\n",
    "# Here 'voting' is set to 'hard'. Change to 'soft' for soft voting if desired\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', rf_pipeline),\n",
    "    ('svm', svm_pipeline),\n",
    "    ('lr', lr_pipeline)\n",
    "], voting='hard')\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the ensemble model\n",
    "predictions = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of ensemble model: {accuracy}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-medicare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "surprised-mandate",
   "metadata": {},
   "source": [
    "### Ensemble hard voting method using random forest, svm, and logistic regression with unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "original-climate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble model: 0.739454094292804\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.82      0.61      0.70       601\n",
      "    POSITIVE       0.69      0.87      0.77       608\n",
      "\n",
      "    accuracy                           0.74      1209\n",
      "   macro avg       0.76      0.74      0.73      1209\n",
      "weighted avg       0.76      0.74      0.74      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined as per your dataset\n",
    "\n",
    "# Define pipelines for each of the classifiers including the TF-IDF vectorization\n",
    "rf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('svm', SVC(probability=True, random_state=42))  # Enable probability for soft voting\n",
    "])\n",
    "\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    ('logreg', LogisticRegression(random_state=42))  # Enable probability for soft voting\n",
    "])\n",
    "\n",
    "\n",
    "# Create the ensemble model using voting classifier\n",
    "# Here 'voting' is set to 'hard'. Change to 'soft' for soft voting if desired\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', rf_pipeline),\n",
    "    ('svm', svm_pipeline),\n",
    "    ('lr', lr_pipeline)\n",
    "], voting='hard')\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the ensemble model\n",
    "predictions = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of ensemble model: {accuracy}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-wheat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "vocal-salad",
   "metadata": {},
   "source": [
    "### Ensemble hard voting method using random forest and SVM\n",
    "### Not used in Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "concerned-charger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble model: 0.7460711331679074\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.79      0.67      0.72       601\n",
      "    POSITIVE       0.72      0.82      0.76       608\n",
      "\n",
      "    accuracy                           0.75      1209\n",
      "   macro avg       0.75      0.75      0.74      1209\n",
      "weighted avg       0.75      0.75      0.74      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined as per your dataset\n",
    "\n",
    "# Define pipelines for each of the classifiers including the TF-IDF vectorization\n",
    "rf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svm', SVC(probability=True, random_state=42))  # Enable probability for soft voting\n",
    "])\n",
    "\n",
    "# Create the ensemble model using voting classifier\n",
    "# Here 'voting' is set to 'hard'. Change to 'soft' for soft voting if desired\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', rf_pipeline),\n",
    "    ('svm', svm_pipeline)\n",
    "], voting='hard')\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the ensemble model\n",
    "predictions = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of ensemble model: {accuracy}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-slope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-concern",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fluid-leone",
   "metadata": {},
   "source": [
    "# Ensemble Stacking Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-depression",
   "metadata": {},
   "source": [
    "### Ensemble stacking method using ZhengWei logreg and MJ SVM with unigram\n",
    "### Not used in project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "external-separate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beh Ming Jun\\anaconda3\\envs\\classify\\lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of stacking ensemble model: 0.7543424317617866\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.78      0.70      0.74       601\n",
      "    POSITIVE       0.73      0.81      0.77       608\n",
      "\n",
      "    accuracy                           0.75      1209\n",
      "   macro avg       0.76      0.75      0.75      1209\n",
      "weighted avg       0.76      0.75      0.75      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "logreg_model = load(\"logreg_model_posneg.joblib\")\n",
    "\n",
    "# Update: Adding Logistic Regression and Multinomial Naive Bayes to the base classifiers\n",
    "base_classifiers = [\n",
    "    ('rf_pipeline', make_pipeline(TfidfVectorizer(), RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('svm_pipeline', make_pipeline(TfidfVectorizer(), SVC(probability=True, random_state=42))),\n",
    "    ('lr_pipeline', make_pipeline(TfidfVectorizer(), logreg_model))\n",
    "]\n",
    "\n",
    "# Keeping Logistic Regression as the meta-classifier\n",
    "meta_classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define the stacking ensemble model\n",
    "stacking_clf = StackingClassifier(estimators=base_classifiers, final_estimator=meta_classifier, cv=5)\n",
    "\n",
    "# Training the stacking ensemble model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting with the stacking ensemble model\n",
    "predictions = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluating the stacking ensemble model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of stacking ensemble model: {accuracy}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = load(\"logreg_model_posneg.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-scholar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "exempt-harassment",
   "metadata": {},
   "source": [
    "### Ensemble stacking method using ZhengWei logreg and MJ SVM with unigram and bigram\n",
    "### Not used in project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "political-future",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beh Ming Jun\\anaconda3\\envs\\classify\\lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of stacking ensemble model: 0.738626964433416\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.75      0.71      0.73       601\n",
      "    POSITIVE       0.73      0.77      0.75       608\n",
      "\n",
      "    accuracy                           0.74      1209\n",
      "   macro avg       0.74      0.74      0.74      1209\n",
      "weighted avg       0.74      0.74      0.74      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "logreg_model = load(\"logreg_model_posneg.joblib\")\n",
    "\n",
    "# Update: Adding Logistic Regression and Multinomial Naive Bayes to the base classifiers\n",
    "base_classifiers = [\n",
    "    ('rf_pipeline', make_pipeline(TfidfVectorizer(ngram_range=(1,2)), RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('svm_pipeline', make_pipeline(TfidfVectorizer(ngram_range=(1,2)), SVC(probability=True, random_state=42))),\n",
    "    ('lr_pipeline', make_pipeline(TfidfVectorizer(ngram_range=(1,2)), logreg_model))\n",
    "]\n",
    "\n",
    "# Keeping Logistic Regression as the meta-classifier\n",
    "meta_classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define the stacking ensemble model\n",
    "stacking_clf = StackingClassifier(estimators=base_classifiers, final_estimator=meta_classifier, cv=5)\n",
    "\n",
    "# Training the stacking ensemble model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting with the stacking ensemble model\n",
    "predictions = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluating the stacking ensemble model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of stacking ensemble model: {accuracy}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-tactics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "solid-singles",
   "metadata": {},
   "source": [
    "### Ensemble Stacking method using random forest, SVM, logreg, naive bayes on unigrams\n",
    "### Not used in project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "looking-ceramic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of stacking ensemble model: 0.7427626137303557\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.80      0.64      0.71       601\n",
      "    POSITIVE       0.70      0.85      0.77       608\n",
      "\n",
      "    accuracy                           0.74      1209\n",
      "   macro avg       0.75      0.74      0.74      1209\n",
      "weighted avg       0.75      0.74      0.74      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Update: Adding Logistic Regression and Multinomial Naive Bayes to the base classifiers\n",
    "base_classifiers = [\n",
    "    ('rf_pipeline', make_pipeline(TfidfVectorizer(), RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('svm_pipeline', make_pipeline(TfidfVectorizer(), SVC(probability=True, random_state=42))),\n",
    "    ('lr_pipeline', make_pipeline(TfidfVectorizer(), LogisticRegression(random_state=42))),\n",
    "    ('nb_pipeline', make_pipeline(TfidfVectorizer(), MultinomialNB()))\n",
    "]\n",
    "\n",
    "# Keeping Logistic Regression as the meta-classifier\n",
    "meta_classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define the stacking ensemble model\n",
    "stacking_clf = StackingClassifier(estimators=base_classifiers, final_estimator=meta_classifier, cv=5)\n",
    "\n",
    "# Training the stacking ensemble model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting with the stacking ensemble model\n",
    "predictions = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluating the stacking ensemble model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of stacking ensemble model: {accuracy}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-johnston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "square-apparel",
   "metadata": {},
   "source": [
    "### Ensemble Stacking method using random forest, SVM, logreg, naive bayes on unigrams and bigrams\n",
    "### Not used in project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wrapped-confidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of stacking ensemble model: 0.739454094292804\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.77      0.67      0.72       601\n",
      "    POSITIVE       0.71      0.80      0.76       608\n",
      "\n",
      "    accuracy                           0.74      1209\n",
      "   macro avg       0.74      0.74      0.74      1209\n",
      "weighted avg       0.74      0.74      0.74      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Update: Adding Logistic Regression and Multinomial Naive Bayes to the base classifiers\n",
    "base_classifiers = [\n",
    "    ('rf_pipeline', make_pipeline(TfidfVectorizer(ngram_range=(1,2)), RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('svm_pipeline', make_pipeline(TfidfVectorizer(ngram_range=(1,2)), SVC(probability=True, random_state=42))),\n",
    "    ('lr_pipeline', make_pipeline(TfidfVectorizer(ngram_range=(1,2)), LogisticRegression(random_state=42))),\n",
    "    ('nb_pipeline', make_pipeline(TfidfVectorizer(ngram_range=(1,2)), MultinomialNB()))\n",
    "]\n",
    "\n",
    "# Keeping Logistic Regression as the meta-classifier\n",
    "meta_classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define the stacking ensemble model\n",
    "stacking_clf = StackingClassifier(estimators=base_classifiers, final_estimator=meta_classifier, cv=5)\n",
    "\n",
    "# Training the stacking ensemble model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting with the stacking ensemble model\n",
    "predictions = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluating the stacking ensemble model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of stacking ensemble model: {accuracy}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-carol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "blind-camcorder",
   "metadata": {},
   "source": [
    "### Ensemble Stacking method using random forest and SVM with only unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "helpful-limit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of stacking ensemble model: 0.7568238213399504\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.78      0.71      0.74       601\n",
      "    POSITIVE       0.74      0.80      0.77       608\n",
      "\n",
      "    accuracy                           0.76      1209\n",
      "   macro avg       0.76      0.76      0.76      1209\n",
      "weighted avg       0.76      0.76      0.76      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Base classifiers for the stacking ensemble, each with a TF-IDF vectorizer\n",
    "base_classifiers = [\n",
    "    ('rf_pipeline', make_pipeline(TfidfVectorizer(), RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('svm_pipeline', make_pipeline(TfidfVectorizer(), SVC(probability=True, random_state=42)))\n",
    "]\n",
    "\n",
    "# Meta-classifier\n",
    "meta_classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "# Stacking ensemble classifier, combining the base classifiers and using a meta-classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_classifiers, final_estimator=meta_classifier, cv=5)\n",
    "\n",
    "# Train the stacking ensemble model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the stacking ensemble model\n",
    "predictions = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the stacking ensemble model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of stacking ensemble model: {accuracy}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-payment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-turner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "accepted-wayne",
   "metadata": {},
   "source": [
    "### Ensemble Stacking method using random forest and SVM with unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "domestic-adrian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of stacking ensemble model: 0.7485525227460711\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.77      0.70      0.73       601\n",
      "    POSITIVE       0.73      0.80      0.76       608\n",
      "\n",
      "    accuracy                           0.75      1209\n",
      "   macro avg       0.75      0.75      0.75      1209\n",
      "weighted avg       0.75      0.75      0.75      1209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Base classifiers for the stacking ensemble, each with a TF-IDF vectorizer\n",
    "base_classifiers = [\n",
    "    ('rf_pipeline', make_pipeline(TfidfVectorizer(ngram_range=(1,2)), RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('svm_pipeline', make_pipeline(TfidfVectorizer(ngram_range=(1,2)), SVC(probability=True, random_state=42)))\n",
    "]\n",
    "\n",
    "# Meta-classifier\n",
    "meta_classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "# Stacking ensemble classifier, combining the base classifiers and using a meta-classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_classifiers, final_estimator=meta_classifier, cv=5)\n",
    "\n",
    "# Train the stacking ensemble model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the stacking ensemble model\n",
    "predictions = stacking_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the stacking ensemble model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy of stacking ensemble model: {accuracy}\")\n",
    "print(\"Classification report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-makeup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-antibody",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "recent-poison",
   "metadata": {},
   "source": [
    "### Saving the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "atmospheric-conviction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to svm_ensemble_stacking_75682.joblib\n"
     ]
    }
   ],
   "source": [
    "# from joblib import dump, load\n",
    "\n",
    "# # Save the model to a file\n",
    "# model_filename = 'svm_ensemble_stacking_75682.joblib'  # Specifying a path in your environment\n",
    "# dump(stacking_clf, model_filename)\n",
    "\n",
    "# print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-suspension",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-maximum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classify",
   "language": "python",
   "name": "classify"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
